{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:35.858751Z",
     "start_time": "2018-12-01T17:57:34.507686Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import EnsembleLda, LdaMulticore\n",
    "from gensim.corpora import OpinosisCorpus\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enable the ensemble logger to show what it is doing currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:36.539523Z",
     "start_time": "2018-12-01T17:57:36.534986Z"
    }
   },
   "outputs": [],
   "source": [
    "elda_logger = logging.getLogger(EnsembleLda.__module__)\n",
    "elda_logger.setLevel(logging.INFO)\n",
    "elda_logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on the Opinosis Dataset\n",
    "\n",
    "Opinosis [1] is a small (but redundant) corpus that contains 289 product reviews for 51 products. Since it's so small, the results are rather unstable.\n",
    "\n",
    "[1] Kavita Ganesan, ChengXiang Zhai, and Jiawei Han, _Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions,_ Proceedings of the 23rd International Conference on Computational Linguistics, Association for Computational Linguistics, 2010, pp. 340â€“348.\n",
    "http://kavita-ganesan.com/opinosis-opinion-dataset/ https://github.com/kavgan/opinosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus\n",
    "\n",
    "First, download the opinosis dataset. On linux it can be done like this for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T20:19:17.891961Z",
     "start_time": "2018-11-29T20:19:16.731678Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir ~/opinosis\n",
    "!wget -P ~/opinosis https://github.com/kavgan/opinosis/raw/master/OpinosisDataset1.0_0.zip\n",
    "!unzip ~/opinosis/OpinosisDataset1.0_0.zip -d ~/opinosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:39.575650Z",
     "start_time": "2018-12-01T17:57:39.571588Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/opinosis/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus and id2word mapping can be created using the load_opinosis_data function provided in the package.\n",
    "It preprocesses the data using the PorterStemmer and stopwords from the nltk package.\n",
    "\n",
    "The parameter of the function is the relative path to the folder, into which the zip file was extracted before. That folder contains a 'summaries-gold' subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:40.842440Z",
     "start_time": "2018-12-01T17:57:39.905273Z"
    }
   },
   "outputs": [],
   "source": [
    "opinosis = OpinosisCorpus(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parameters**\n",
    "\n",
    "**topic_model_kind** ldamulticore is highly recommended for EnsembleLda. ensemble_workers and **distance_workers** are used to improve the time needed to train the models, as well as the **masking_method** 'rank'. ldamulticore is not able to fully utilize all cores on this small corpus, so **ensemble_workers** can be set to 3 to get 95 - 100% cpu usage on my i5 3470.\n",
    "\n",
    "Since the corpus is so small, a high number of **num_models** is needed to extract stable topics. The Opinosis corpus contains 51 categories, however, some of them are quite similar. For example there are 3 categories about the batteries of portable products. There are also multiple categories about cars. So I chose 20 for num_topics, which is smaller than the number of categories.\n",
    "\n",
    "The default for **min_samples** would be 64, half of the number of models. But since this does not return any topics, or at most 2, I set this to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:10:13.690983Z",
     "start_time": "2018-12-01T17:57:41.089661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 128 topic models...\n",
      "Spawned worker to generate 42 topic models\n",
      "Spawned worker to generate 43 topic models\n",
      "Spawned worker to generate 43 topic models\n",
      "Generating a 2560 x 2560 asymmetric distance matrix...\n",
      "Spawned worker to generate 640 rows of the asymmetric distance matrix\n",
      "Spawned worker to generate 640 rows of the asymmetric distance matrix\n",
      "Spawned worker to generate 640 rows of the asymmetric distance matrix\n",
      "Spawned worker to generate 640 rows of the asymmetric distance matrix\n",
      "The given threshold of 0.11 covered on average 9.9% of tokens\n",
      "The given threshold of 0.11 covered on average 9.8% of tokens\n",
      "The given threshold of 0.11 covered on average 9.9% of tokens\n",
      "The given threshold of 0.11 covered on average 9.8% of tokens\n",
      "Fitting the clustering model\n",
      "Generating stable topics\n",
      "Generating classic gensim model representation based on results from the ensemble\n"
     ]
    }
   ],
   "source": [
    "elda = EnsembleLda(corpus=opinosis.corpus, id2word=opinosis.id2word, num_models=128, num_topics=20,\n",
    "                   passes=20, iterations=100, ensemble_workers=3, distance_workers=4,\n",
    "                   topic_model_kind='ldamulticore', masking_method='rank', min_samples=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:10:13.712818Z",
     "start_time": "2018-12-01T18:10:13.695844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0.132 staff, 0.082 servic, 0.081 friendli, 0.075 help, 0.021 good, 0.015 quick, 0.010 expens \n",
      "\n",
      "- 0.166 screen, 0.063 bright, 0.040 clear, 0.022 easi, 0.020 touch, 0.015 read, 0.014 new \n",
      "\n",
      "- 0.146 free, 0.043 park, 0.034 coffe, 0.031 wine, 0.025 even, 0.025 morn, 0.022 internet \n",
      "\n",
      "- 0.142 batteri, 0.099 life, 0.026 short, 0.020 charg, 0.018 kindl, 0.018 good, 0.017 perform \n",
      "\n",
      "- 0.123 room, 0.111 clean, 0.050 small, 0.035 comfort, 0.033 bathroom, 0.017 nice, 0.016 size \n",
      "\n",
      "- 0.147 seat, 0.086 comfort, 0.058 uncomfort, 0.045 firm, 0.031 long, 0.030 drive, 0.014 time \n",
      "\n",
      "- 0.161 mileag, 0.106 ga, 0.056 good, 0.028 expect, 0.019 hard, 0.018 road, 0.018 high \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretty print, note that the words are stemmed so they appear chopped off\n",
    "for t in elda.print_topics(num_words=7):\n",
    "    print('-', t[1].replace('*',' ').replace('\"','').replace(' +',','), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
