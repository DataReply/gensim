{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:35.858751Z",
     "start_time": "2018-12-01T17:57:34.507686Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import EnsembleLda, LdaMulticore\n",
    "from gensim.corpora import OpinosisCorpus\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enable the ensemble logger to show what it is doing currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:36.539523Z",
     "start_time": "2018-12-01T17:57:36.534986Z"
    }
   },
   "outputs": [],
   "source": [
    "elda_logger = logging.getLogger(EnsembleLda.__module__)\n",
    "elda_logger.setLevel(logging.INFO)\n",
    "elda_logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on the Opinosis Dataset\n",
    "\n",
    "Opinosis is an extremely small corpus that contains 289 product reviews for 51 products, which is why it is hard to extract topics from it. https://github.com/kavgan/opinosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus\n",
    "\n",
    "First, download the opinosis dataset. On linux it can be done like this for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T20:19:17.891961Z",
     "start_time": "2018-11-29T20:19:16.731678Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir ~/opinosis\n",
    "!wget -P ~/opinosis https://github.com/kavgan/opinosis/raw/master/OpinosisDataset1.0_0.zip\n",
    "!unzip ~/opinosis/OpinosisDataset1.0_0.zip -d ~/opinosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:39.575650Z",
     "start_time": "2018-12-01T17:57:39.571588Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/opinosis/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus and id2word mapping can be created using the load_opinosis_data function provided in the package.\n",
    "It preprocesses the data using the PorterStemmer and stopwords from the nltk package.\n",
    "\n",
    "The parameter of the function is the relative path to the folder, into which the zip file was extracted before. That folder contains a 'summaries-gold' subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T17:57:40.842440Z",
     "start_time": "2018-12-01T17:57:39.905273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data source:\n",
      "title:\t\tOpinosis: a graph-based approach to abstractive summarization of highly redundant opinions\n",
      "authors:\tGanesan, Kavita and Zhai, ChengXiang and Han, Jiawei\n",
      "booktitle:\tProceedings of the 23rd International Conference on Computational Linguistics\n",
      "pages:\t\t340-348\n",
      "year:\t\t2010\n",
      "organization:\tAssociation for Computational Linguistics\n"
     ]
    }
   ],
   "source": [
    "opinosis = OpinosisCorpus(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parameters**\n",
    "\n",
    "**topic_model_kind** ldamulticore is highly recommended for EnsembleLda. ensemble_workers and **distance_workers** are used to improve the time needed to train the models, as well as the **masking_method** 'rank'. ldamulticore is not able to fully utilize all cores on this small corpus, so **ensemble_workers** can be set to 3 to get 95 - 100% cpu usage on my i5 3470.\n",
    "\n",
    "Since the corpus is so small, a high number of **num_models** is needed to extract stable topics. The Opinosis corpus contains 51 categories, however, some of them are quite similar. For example there are 3 categories about the batteries of portable products. There are also multiple categories about cars. So I chose 20 for num_topics, which is smaller than the number of categories.\n",
    "\n",
    "The default for **min_samples** would be 64, half of the number of models. But since this does not return any topics, or at most 2, I set this to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:10:13.690983Z",
     "start_time": "2018-12-01T17:57:41.089661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawned worker to generate 42 topic models...\n",
      "Spawned worker to generate 43 topic models...\n",
      "Generating 42 topic models...\n",
      "Generating 43 topic models...\n",
      "Spawned worker to generate 43 topic models...\n",
      "Generating 43 topic models...\n",
      "Spawned worker to generate 640 rows of the asymmetric similarity matrix...\n",
      "Spawned worker to generate 640 rows of the asymmetric similarity matrix...\n",
      "Spawned worker to generate 640 rows of the asymmetric similarity matrix...\n",
      "Spawned worker to generate 640 rows of the asymmetric similarity matrix...\n",
      "Fitting the clustering model\n",
      "Generating stable topics\n",
      "Generating classic gensim model representation based on results from the ensemble\n"
     ]
    }
   ],
   "source": [
    "elda = EnsembleLda(corpus=opinosis.corpus, id2word=opinosis.id2word, num_models=128, num_topics=20,\n",
    "                   passes=20, iterations=100, ensemble_workers=3, distance_workers=4,\n",
    "                   topic_model_kind='ldamulticore', masking_method='rank', min_samples=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:10:13.712818Z",
     "start_time": "2018-12-01T18:10:13.695844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0.145 free, 0.043 park, 0.033 coffe, 0.030 wine, 0.027 even, 0.025 morn, 0.022 internet \n",
      "\n",
      "- 0.161 screen, 0.062 bright, 0.043 clear, 0.027 easi, 0.021 read, 0.019 touch, 0.011 size \n",
      "\n",
      "- 0.127 staff, 0.075 friendli, 0.074 help, 0.070 servic, 0.016 quick, 0.012 profession, 0.012 good \n",
      "\n",
      "- 0.123 seat, 0.067 comfort, 0.050 uncomfort, 0.039 front, 0.037 back, 0.036 firm, 0.032 drive \n",
      "\n",
      "- 0.113 room, 0.104 clean, 0.041 small, 0.037 bathroom, 0.036 comfort, 0.023 size, 0.016 well \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretty print, note that the words are stemmed so they appear chopped off\n",
    "for t in elda.print_topics(num_words=7):\n",
    "    print('-', t[1].replace('*',' ').replace('\"','').replace(' +',','), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
